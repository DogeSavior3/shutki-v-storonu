{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62380c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting greek-stemmer-pos\n",
      "  Downloading greek_stemmer_pos-1.1.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pytest in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from greek-stemmer-pos) (8.3.3)\n",
      "Collecting pytest-cov (from greek-stemmer-pos)\n",
      "  Downloading pytest_cov-6.0.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: iniconfig in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (2.0.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (23.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (1.2.2)\n",
      "Requirement already satisfied: tomli>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (2.1.0)\n",
      "Collecting coverage>=7.5 (from coverage[toml]>=7.5->pytest-cov->greek-stemmer-pos)\n",
      "  Downloading coverage-7.6.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.2 kB)\n",
      "Downloading greek_stemmer_pos-1.1.2-py3-none-any.whl (19 kB)\n",
      "Downloading pytest_cov-6.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading coverage-7.6.8-cp310-cp310-macosx_11_0_arm64.whl (207 kB)\n",
      "Installing collected packages: coverage, pytest-cov, greek-stemmer-pos\n",
      "Successfully installed coverage-7.6.8 greek-stemmer-pos-1.1.2 pytest-cov-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install greek-stemmer-pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa2e119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from greek_stemmer import stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11619d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"pure\"\n",
    "output_folder = \"stemmed_greek_literature_pure\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a3b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    def preprocess_word(word):\n",
    "        word = word.upper()\n",
    "        word = word.replace(\"Ά\", \"Α\").replace(\"Έ\", \"Ε\").replace(\"Ή\", \"Η\").replace(\"Ί\", \"Ι\") \\\n",
    "                   .replace(\"Ό\", \"Ο\").replace(\"Ύ\", \"Υ\").replace(\"Ώ\", \"Ω\") \\\n",
    "                   .replace(\"ΐ\", \"Ι\").replace(\"Ϊ\", \"Ι\").replace(\"Ϋ\", \"Υ\") \\\n",
    "                   .replace(\"ά\", \"Α\").replace(\"έ\", \"Ε\").replace(\"ή\", \"Η\").replace(\"ί\", \"Ι\") \\\n",
    "                   .replace(\"ύ\", \"Υ\").replace(\"ό\", \"Ο\").replace(\"ώ\", \"Ω\") \\\n",
    "                   .replace(\"ϊ\", \"Ι\").replace(\"ϋ\", \"Υ\").replace(\"ΐ\", \"Ι\").replace(\"ΰ\", \"Υ\")\n",
    "        return word\n",
    "    \n",
    "    words = text.split()\n",
    "    preprocessed_words = [stemmer.stem_word(preprocess_word(word), 'VBG').lower() for word in words]  # 'VBG' - Part of Speech (пример)\n",
    "    return ' '.join(preprocessed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a8fcb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка завершена\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        stemmed_text = stem_text(text)\n",
    "        \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(stemmed_text)\n",
    "\n",
    "print(\"Обработка завершена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43dd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86e517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19921931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff423761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39fc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba221983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c355bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50bc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "\n",
    "nlp = spacy.load('el_core_news_lg', disable=['parser'])\n",
    "nlp.max_length = 5000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe743db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"example\"\n",
    "output_folder = \"example_processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8117a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_greek_text(text):\n",
    "    pos_dict = {'PROPN': 'person1', 'PRON': 'pron1', 'NUM': 'ordinal1'}\n",
    "    preprocessed_text = text.strip()\n",
    "    nlp_doc = nlp(preprocessed_text)\n",
    "    result = []\n",
    "\n",
    "    for token in nlp_doc:\n",
    "        if token.pos_ in pos_dict:\n",
    "            result.append(pos_dict[token.pos_])\n",
    "        elif token.lemma_.isdigit():\n",
    "            result.append('ordinal1')\n",
    "        elif token.pos_ != 'PUNCT':\n",
    "            result.append(token.text)\n",
    "    \n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12181e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        prepared_text = prepare_greek_text(text)\n",
    "        \n",
    "        stemmed_text = stem_text(prepared_text)\n",
    "        \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(stemmed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031362f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff32734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc0622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e3521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73876ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d784d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка завершена\n"
     ]
    }
   ],
   "source": [
    "def prepare_greek_text(text):\n",
    "    \"\"\"Заменить определенные слова на токены и вернуться к обработанным словам\"\"\"\n",
    "    pos_dict = {'PROPN': 'person1', 'PRON': 'pron1', 'NUM': 'ordinal1'}\n",
    "    preprocessed_text = text.strip()\n",
    "    nlp_doc = nlp(preprocessed_text)\n",
    "    result = []\n",
    "\n",
    "    for token in nlp_doc:\n",
    "        if token.pos_ in pos_dict:\n",
    "            result.append((token.text, pos_dict[token.pos_]))\n",
    "        elif token.lemma_.isdigit():\n",
    "            result.append((token.text, 'ordinal1'))\n",
    "        elif token.pos_ != 'PUNCT':\n",
    "            result.append((token.text, token.text))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def stem_text(words):\n",
    "    stemmed_words = [(word, stemmer.stem_word(preprocess_word(word), 'VBG').lower()) for word in words]  # 'VBG' - Part of Speech (пример)\n",
    "    return stemmed_words\n",
    "\n",
    "def preprocess_word(word):\n",
    "        word = word.upper()\n",
    "        word = word.replace(\"Ά\", \"Α\").replace(\"Έ\", \"Ε\").replace(\"Ή\", \"Η\").replace(\"Ί\", \"Ι\") \\\n",
    "                   .replace(\"Ό\", \"Ο\").replace(\"Ύ\", \"Υ\").replace(\"Ώ\", \"Ω\") \\\n",
    "                   .replace(\"ΐ\", \"Ι\").replace(\"Ϊ\", \"Ι\").replace(\"Ϋ\", \"Υ\") \\\n",
    "                   .replace(\"ά\", \"Α\").replace(\"έ\", \"Ε\").replace(\"ή\", \"Η\").replace(\"ί\", \"Ι\") \\\n",
    "                   .replace(\"ύ\", \"Υ\").replace(\"ό\", \"Ο\").replace(\"ώ\", \"Ω\") \\\n",
    "                   .replace(\"ϊ\", \"Ι\").replace(\"ϋ\", \"Υ\").replace(\"ΐ\", \"Ι\").replace(\"ΰ\", \"Υ\")\n",
    "        return word\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        prepared_words = prepare_greek_text(text)\n",
    "        stemmed_words = stem_text([word for word, _ in prepared_words])\n",
    "        \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            for original, stemmed in stemmed_words:\n",
    "                file.write(f\"{original} {stemmed}\\n\")\n",
    "\n",
    "print(\"Обработка завершена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa513936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining files...\n",
      "Combining completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_folder = \"example\"\n",
    "output_file = \"combined_output.txt\"\n",
    "\n",
    "def combine_files(input_folder, output_file):\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for filename in os.listdir(input_folder):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                input_path = os.path.join(input_folder, filename)\n",
    "                with open(input_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "                    for line in infile:\n",
    "                        stripped_line = line.strip()\n",
    "                        if stripped_line:\n",
    "                            outfile.write(stripped_line + \"\\n\")\n",
    "                            \n",
    "print(\"Combining files...\")\n",
    "combine_files(input_folder, output_file)\n",
    "print(\"Combining completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d2f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

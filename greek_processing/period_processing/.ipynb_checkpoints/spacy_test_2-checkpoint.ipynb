{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4100b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grecy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement grc_perseus_lg (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for grc_perseus_lg\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Invalid requirement: 'grc-proiel-trf==any': Expected end or semicolon (after name and no valid version specifier)\n",
      "    grc-proiel-trf==any\n",
      "                  ^\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install grecy grc_perseus_lg\n",
    "!pip install https://huggingface.co/Jacobo/grc_proiel_trf/resolve/main/grc_proiel_trf-any-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4af76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('grecy/grc_perseus_trf')\n",
    "nlp.max_length = 50000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ba8047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Αυτή', 'Αυτή', 'PRON'), ('είναι', 'είναι', 'AUX'), ('μια', 'μια', 'ADJ'), ('πρόταση', 'πρόταση', 'NOUN'), ('.', '.', 'PUNCT'), ('αυτοί', 'αυτός', 'ADJ')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  # NB: Previously this was torch.cuda.amp.autocast, passing a boolean\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Αυτή είναι μια πρόταση. αυτοί\")\n",
    "lemmas = [(w.text, w.lemma_, w.pos_) for w in doc]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4109b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pos_dict = {'PROPN': 'person1', 'PRON': 'pron1', 'NUM': 'ordinal1'}\n",
    "\n",
    "def process_all_files(pure_folder, processed_folder, batch_size=5):\n",
    "    if not os.path.exists(processed_folder):\n",
    "        os.makedirs(processed_folder)\n",
    "    \n",
    "    files = [f for f in os.listdir(pure_folder) if f.endswith('.txt')]\n",
    "        nlp_doc = nlp(combined_text)\n",
    "\n",
    "        splits = combined_text.split(\"<br>\")\n",
    "        for idx, filename in enumerate(file_names):\n",
    "            output_file = os.path.join(processed_folder, filename)\n",
    "            with open(output_file, 'w') as f:\n",
    "                for token in nlp_doc:\n",
    "                    if token.text in splits[idx]:\n",
    "                        if token.pos_ in pos_dict:\n",
    "                            f.write(f\"{pos_dict[token.pos_]} \")\n",
    "                        elif token.lemma_.isdigit():\n",
    "                            f.write(f\"{token.lemma_} ordinal1 \")\n",
    "                        elif token.pos_ != 'PUNCT':\n",
    "                            f.write(f\"{token.lemma_.lower()} \")\n",
    "            print(f\"Wrote processed text to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579aae19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pure/Fragmentum (193).txt\n",
      "Reading pure/Titulus (24).txt\n",
      "Reading pure/De theologia .txt\n",
      "Reading pure/Celtica .txt\n",
      "Reading pure/De lapidibus .txt\n",
      "Wrote processed text to greek_lemmatized_perseus/Fragmentum (193).txt\n",
      "Wrote processed text to greek_lemmatized_perseus/Titulus (24).txt\n",
      "Wrote processed text to greek_lemmatized_perseus/De theologia .txt\n",
      "Wrote processed text to greek_lemmatized_perseus/Celtica .txt\n",
      "Wrote processed text to greek_lemmatized_perseus/De lapidibus .txt\n",
      "Reading pure/Parasceuastica et poliorcetica.txt\n",
      "Reading pure/De mensuris et ponderibus  (5).txt\n",
      "Reading pure/Fragmenta (590).txt\n",
      "Reading pure/Εἰς τὸν αὐτοκράτορα Κωνστάντιον .txt\n",
      "Reading pure/Catastases.txt\n",
      "Wrote processed text to greek_lemmatized_perseus/Parasceuastica et poliorcetica.txt\n",
      "Wrote processed text to greek_lemmatized_perseus/De mensuris et ponderibus  (5).txt\n",
      "Wrote processed text to greek_lemmatized_perseus/Fragmenta (590).txt\n",
      "Wrote processed text to greek_lemmatized_perseus/Εἰς τὸν αὐτοκράτορα Κωνστάντιον .txt\n",
      "Wrote processed text to greek_lemmatized_perseus/Catastases.txt\n",
      "Reading pure/Certamen Homeri et Hesiodi.txt\n",
      "Reading pure/Fragmenta in Matthaeum  (1).txt\n",
      "Reading pure/De vocabulis quae diversum significatum exhibent secundum differentiam accentus .txt\n",
      "Reading pure/De communi mathematica scientia.txt\n",
      "Reading pure/Lexicon  (2).txt\n"
     ]
    }
   ],
   "source": [
    "pure_folder = 'pure'\n",
    "processed_folder = 'greek_lemmatized_perseus'\n",
    "process_all_files(pure_folder, processed_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce63856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

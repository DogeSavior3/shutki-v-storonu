{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b1bfbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1895443587.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python -m spacy download el_core_news_lg\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m spacy download el_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5f1b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"el_core_news_lg\")\n",
    "import el_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c6029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e636c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Αυτή', 'Αυτός', 'PRON'), ('είναι', 'είμαι', 'AUX'), ('μια', 'ένας', 'DET'), ('πρόταση', 'πρόταση', 'NOUN'), ('.', '.', 'PUNCT'), ('αυτοί', 'αυτός', 'PRON')]\n"
     ]
    }
   ],
   "source": [
    "nlp = el_core_news_lg.load(disable=['parser'])\n",
    "nlp.max_length = 5000000\n",
    "doc = nlp(\"Αυτή είναι μια πρόταση. αυτοί\")\n",
    "lemmas = [(w.text, w.lemma_, w.pos_) for w in doc]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09cbce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = ['με', 'μας',\n",
    "'σε', 'σας',\n",
    "'τον', 'τους',\n",
    "'την', 'τις',\n",
    "'το', 'τα',\n",
    "'μου', 'μας',\n",
    "'σου', 'σας',\n",
    "'του', 'τους',\n",
    "'της', 'τους',\n",
    "'του', 'τους',\n",
    "'εγώ', 'εμείς',\n",
    "'εσύ', 'εσείς',\n",
    "'αυτός', 'αυτοί',\n",
    "'αυτή', 'αυτές',\n",
    "'αυτό', 'αυτά']\n",
    "numerals = [\n",
    "    \"ένα\",\n",
    "    \"δύο\",\n",
    "    \"τρία\",\n",
    "    \"τέσσερα\",\n",
    "    \"πέντε\",\n",
    "    \"έξι\",\n",
    "    \"επτά\",\n",
    "    \"οκτώ\",\n",
    "    \"εννέα\",\n",
    "    \"δέκα\",\n",
    "    \"είκοσι\",\n",
    "    \"τριάντα\",\n",
    "    \"σαράντα\",\n",
    "    \"πενήντα\",\n",
    "    \"εξήντα\",\n",
    "    \"εβδομήντα\",\n",
    "    \"ογδόντα\",\n",
    "    \"ενενήντα\",\n",
    "    \"εκατό\",\n",
    "    \"διακόσια\",\n",
    "    \"τριακόσια\",\n",
    "    \"τετρακόσια\",\n",
    "    \"πεντακόσια\",\n",
    "    \"εξακόσια\",\n",
    "    \"επτακόσια\",\n",
    "    \"οκτακόσια\",\n",
    "    \"εννιακόσια\",\n",
    "    \"χίλια\",\n",
    "    \"δέκα χιλιάδες\",\n",
    "    \"εκατό χιλιάδες\",\n",
    "    \"ένα εκατομμύριο\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa0a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    words_to_remove = noun + numerals\n",
    "    \n",
    "    for word in words_to_remove:\n",
    "        text = text.replace(word, '')\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = ' '.join([token.lemma_ for token in doc])\n",
    "    \n",
    "    return lemmatized_text\n",
    "\n",
    "def process_files(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            processed_text = process_text(text)\n",
    "            \n",
    "            with open(file_path, 'w') as f:\n",
    "                f.write(processed_text)\n",
    "\n",
    "# directories = [\"Ancient Greek Literature\", \"Central Greek Literature\"]\n",
    "\n",
    "# for directory in directories:\n",
    "#     process_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767130e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('Ζωσίμου τοῦ Πανοπολίτου γνησία γραφὴ περὶ τῆς ἱερᾶς καὶ θείας τέχνης, τῆς του χρυσοῦ καὶ ἀργύρου ποιήσεως κατ’ ἐπιτομὴνκεφαλαιώδη')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c89a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('el_core_news_lg', disable=['parser'])\n",
    "nlp.max_length = 5000000\n",
    "\n",
    "def prepare_greek_text(input_file, output_file):\n",
    "    pos_dict = {'PROPN': 'person1', 'PRON': 'pron1', 'NUM': 'ordinal1'}\n",
    "    fin = open(input_file, 'r')\n",
    "    with open(output_file, 'w') as prepared_text:\n",
    "        for line in fin:\n",
    "            preprocessed_text = line.strip()\n",
    "            nlp_doc = nlp(preprocessed_text)\n",
    "            for token in nlp_doc:\n",
    "                if token.pos_ in pos_dict:\n",
    "                    prepared_text.write(pos_dict[token.pos_])\n",
    "                    prepared_text.write(' ')\n",
    "                elif token.lemma_.isdigit():\n",
    "                    prepared_text.write('ordinal1')\n",
    "                    prepared_text.write(' ')\n",
    "                elif token.pos_ != 'PUNCT':\n",
    "                    prepared_text.write(token.lemma_.lower())\n",
    "                    prepared_text.write(' ')\n",
    "            prepared_text.write('\\n')\n",
    "    fin.close()\n",
    "\n",
    "def process_all_files(pure_folder, processed_folder):\n",
    "    if not os.path.exists(processed_folder):\n",
    "        os.makedirs(processed_folder)\n",
    "    \n",
    "    for filename in os.listdir(pure_folder):\n",
    "        if filename.endswith('.txt'):\n",
    "            input_file = os.path.join(pure_folder, filename)\n",
    "            output_file = os.path.join(processed_folder, filename)\n",
    "            print(f\"Processing {input_file} -> {output_file}\")\n",
    "            prepare_greek_text(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3ff4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_folder = 'pure'\n",
    "processed_folder = 'processed'\n",
    "process_all_files(pure_folder, processed_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7e47ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing example/MariaPolidouri.txt -> example_processed/MariaPolidouri.txt\n",
      "Processing example/Commentarius in Isaiam.txt -> example_processed/Commentarius in Isaiam.txt\n",
      "Processing example/Aristotle Politics.txt -> example_processed/Aristotle Politics.txt\n",
      "Processing example/Epistula — копия.txt -> example_processed/Epistula — копия.txt\n"
     ]
    }
   ],
   "source": [
    "pure_folder = 'example'\n",
    "processed_folder = 'example_processed'\n",
    "process_all_files(pure_folder, processed_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9ec92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing example/new_exmp.txt -> example_processed/new_exmp.txt\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import os\n",
    "\n",
    "nlp = spacy.load('el_core_news_lg', disable=['parser'])\n",
    "nlp.max_length = 5000000\n",
    "\n",
    "def prepare_greek_text(input_file, output_file):\n",
    "    pos_dict = {'PROPN': 'person1', 'PRON': 'pron1', 'NUM': 'ordinal1'}\n",
    "    fin = open(input_file, 'r')\n",
    "    with open(output_file, 'w') as prepared_text:\n",
    "        for line in fin:\n",
    "            preprocessed_text = line.strip()\n",
    "            nlp_doc = nlp(preprocessed_text)\n",
    "            for token in nlp_doc:\n",
    "                if token.pos_ in pos_dict:\n",
    "                    prepared_text.write(f\"{token.text} {pos_dict[token.pos_]}\\n\")\n",
    "                elif token.lemma_.isdigit():\n",
    "                    prepared_text.write(f\"{token.text} ordinal1\\n\")\n",
    "                elif token.pos_ != 'PUNCT':\n",
    "                    prepared_text.write(f\"{token.text} {token.lemma_.lower()}\\n\")\n",
    "    fin.close()\n",
    "\n",
    "def process_all_files(pure_folder, processed_folder):\n",
    "    if not os.path.exists(processed_folder):\n",
    "        os.makedirs(processed_folder)\n",
    "    \n",
    "    for filename in os.listdir(pure_folder):\n",
    "        if filename.endswith('.txt'):\n",
    "            input_file = os.path.join(pure_folder, filename)\n",
    "            output_file = os.path.join(processed_folder, filename)\n",
    "            print(f\"Processing {input_file} -> {output_file}\")\n",
    "            prepare_greek_text(input_file, output_file)\n",
    "\n",
    "pure_folder = 'example'\n",
    "processed_folder = 'example_processed'\n",
    "process_all_files(pure_folder, processed_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cff5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be8b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tqdm\n",
    "def make_corpus(input_path, output_file_path):\n",
    "\n",
    "    file_list = sorted(glob.glob(input_path + '/*'))\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for file in tqdm.tqdm(file_list):\n",
    "            with open(file, 'r') as input_file:\n",
    "                output_file.write(input_file.read().replace('\\n', ' '))\n",
    "                output_file.write('\\n')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def make_matrix_W_list_of_words(corpus_path, min_df, max_df=None, token_pattern = None, use_idf = True):\n",
    "    with open(corpus_path, 'r') as corpus_file:\n",
    "        if token_pattern:\n",
    "            vectorizer = TfidfVectorizer(analyzer='word', min_df=min_df, token_pattern=token_pattern, use_idf=use_idf)\n",
    "        else:\n",
    "            vectorizer = TfidfVectorizer(analyzer='word', min_df=min_df, use_idf=use_idf)\n",
    "        data_vectorized = vectorizer.fit_transform(corpus_file)\n",
    "    return data_vectorized, vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be537d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 6494/6494 [00:03<00:00, 2145.50it/s]\n"
     ]
    }
   ],
   "source": [
    "make_corpus('stemmed_hebrew_literature', 'corpus_hebrew_literature_stem.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399b5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pattern = 'אבגדהוזחטיכלמנסעפצקרשתךםןףץ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7ed114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, words_list  = make_matrix_W_list_of_words('corpus_hebrew_literature_stem.txt', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f567294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6494, 795170)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b12cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 6494/6494 [00:03<00:00, 1624.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6494, 795170)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_corpus('cleaned', 'corpus_dirty_hebrew.txt')\n",
    "W, words_list  = make_matrix_W_list_of_words('corpus_dirty_hebrew.txt', 1)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cdae22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19bae30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1fa6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svd(W, k, output_folder):\n",
    "    '''\n",
    "    W - matrix texts x words\n",
    "    k - the rank of the SVD, must be less than any dimension of W\n",
    "    '''\n",
    "    u, sigma, vt = svds(W, k)\n",
    "    \n",
    "    descending_order_of_inds = np.flip(np.argsort(sigma))\n",
    "    u = u[:,descending_order_of_inds]\n",
    "    vt = vt[descending_order_of_inds]\n",
    "    sigma = sigma[descending_order_of_inds]\n",
    "\n",
    "    assert sigma.shape == (k,)\n",
    "    assert vt.shape == (k, W.shape[1])\n",
    "    assert u.shape == (W.shape[0], k)\n",
    "\n",
    "    with open(output_folder+'/' + str(k) + '_sigma_vt.npy', 'wb') as f:\n",
    "        np.save(f, np.dot(np.diag(sigma), vt).T)\n",
    "    with open(output_folder+'/' +  str(k) + '_sigma.npy', 'wb') as f:\n",
    "        np.save(f, sigma)\n",
    "    with open(output_folder+'/' +  str(k) + '_u.npy', 'wb') as f:\n",
    "        np.save(f, u)\n",
    "    with open(output_folder+'/' +  str(k) + '_vt.npy', 'wb') as f:\n",
    "        np.save(f, vt)\n",
    "    return np.dot(np.diag(sigma), vt).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60781fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = apply_svd(W, 1024, '/svd_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347f136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

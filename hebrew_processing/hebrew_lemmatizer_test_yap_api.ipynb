{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210beba2",
   "metadata": {
    "id": "210beba2"
   },
   "outputs": [],
   "source": [
    "!pip -q install hebrew-tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73c10e",
   "metadata": {
    "id": "0d73c10e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import hebrew_tokenizer as ht\n",
    "import json\n",
    "\n",
    "# URL для YAP REST API\n",
    "YAP_API_URL = 'http://localhost:8000/yap/heb/joint'\n",
    "\n",
    "pos_dict = {'PROPN': 'person1', 'PRON': 'pron1', 'NUM': 'ordinal1'}\n",
    "\n",
    "def get_lemmas_and_pos(text):\n",
    "    tokens = [token for _, token, _, _ in ht.tokenize(text) if token.strip()]\n",
    "\n",
    "    yap_input = json.dumps({'text': '\\n'.join(tokens) + '  '})\n",
    "\n",
    "    headers = {'content-type': 'application/json'}\n",
    "    response = requests.post(url=YAP_API_URL, data=yap_input, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Ответ:\", response.text)\n",
    "        return []\n",
    "\n",
    "    yap_output = response.json()\n",
    "\n",
    "    lemmas_and_pos = []\n",
    "\n",
    "    if 'ma_lattice' in yap_output:\n",
    "        ma_lattice = yap_output['ma_lattice']\n",
    "        for line in ma_lattice.strip().split('\\n'):\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) > 5:\n",
    "                lemma = parts[2]\n",
    "                pos = parts[4]\n",
    "                lemmas_and_pos.append((lemma, pos))\n",
    "\n",
    "    return lemmas_and_pos\n",
    "\n",
    "def prepare_hebrew_text(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as fin:\n",
    "        text = fin.read()\n",
    "\n",
    "    tokens = [token for _, token, _, _ in ht.tokenize(text) if token.strip()]\n",
    "\n",
    "    lemmas_and_pos = get_lemmas_and_pos('\\n'.join(tokens))\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as prepared_text:\n",
    "        seen_tokens = set()\n",
    "        for lemma, pos in lemmas_and_pos:\n",
    "            if lemma not in seen_tokens:\n",
    "                seen_tokens.add(lemma)\n",
    "                if pos in pos_dict:\n",
    "                    prepared_text.write(pos_dict[pos])\n",
    "                elif lemma.isdigit():\n",
    "                    prepared_text.write('ordinal1')\n",
    "                elif pos != 'PUNCT':\n",
    "                    prepared_text.write(lemma)\n",
    "                prepared_text.write(' ')\n",
    "        prepared_text.write('\\n')\n",
    "\n",
    "def process_all_files(pure_folder, processed_folder):\n",
    "    if not os.path.exists(processed_folder):\n",
    "        os.makedirs(processed_folder)\n",
    "\n",
    "    for filename in os.listdir(pure_folder):\n",
    "        if filename.endswith('.txt'):\n",
    "            input_file = os.path.join(pure_folder, filename)\n",
    "            output_file = os.path.join(processed_folder, filename)\n",
    "            print(f\"Processing {input_file} -> {output_file}\")\n",
    "            prepare_hebrew_text(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d69f5",
   "metadata": {
    "id": "4d1d69f5",
    "outputId": "19a16f63-3b0b-44fd-9f48-021f95e77d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test1/תקוה ופחד.txt -> test2/תקוה ופחד.txt\n"
     ]
    }
   ],
   "source": [
    "pure_folder = 'test1'\n",
    "processed_folder = 'test2'\n",
    "\n",
    "process_all_files(pure_folder, processed_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90892363",
   "metadata": {
    "id": "90892363",
    "outputId": "6c254c59-1ad8-4b96-f1cf-15749a7be11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "tokens = ['יש', 'וביום', 'זה', 'יתנפנפו', 'דגלים', 'שחורים', 'מעל', 'בתיהם', 'של', 'סובאי']\n",
    "\n",
    "yap_input = json.dumps({'tokens': tokens})\n",
    "\n",
    "headers = {'content-type': 'application/json'}\n",
    "response = requests.post(url=YAP_API_URL, data=yap_input, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    yap_output = response.json()\n",
    "    print(json.dumps(yap_output, ensure_ascii=False, indent=4))\n",
    "else:\n",
    "    print(\"Ответ:\", response.text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
